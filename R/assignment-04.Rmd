---
title: "EDS 222: Assignment 04 (due: Nov 23, 5pm)"
author: "Colleen McCamy"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load all the packages needed here
library(tidyverse)
library(readr)
library(gt)
library(tufte)
library(feasts)
library(janitor)
library(lubridate)

# Set your filepath here! Or, set this up as an .Rproj if you'd like.
rootdir <- ("/Users/colleenmccamy/Documents/MEDS/EDS_222_Stats")
setwd(file.path(rootdir,"homework","HW4"))
```

# Question 1: Frosty

In this question we will consider differences in climate conditions across the U.S. states, and conduct a simple hypothesis test.

## Question 1.1

Load the "US State Facts and Figures" dataset called `state.x77`, which is pre-loaded in `R` and contains a variety of statistics for each state. We will be using the `Frost` variable, which contains the mean number of days with minimum temperature below freezing (mean over the years 1931-1960).

Additionally, load the `state.region` dataset, which tells you the region (South, West, Northeast, North Central) that each of the 50 U.S. states falls into. Append these two datasets together (e.g., using `add_column()` from `dplyr`) so that you have one dataset containing the variables in `state.x77` as well as the region for each state.

```{r}
# reading in the data
state_df <- state.x77
state_region_df <- tibble(state.region)

# combining the data
state_df <- state_df |>
  cbind(state_region_df) |> 
  janitor::clean_names()

```

Compute the mean and standard deviation of the number of days below freezing in each region. Report these summary statistics in a table.[^1] Which region has the highest variance in number of frost days?

[^1]: No need to format the table nicely, just print out your summary stats.

**The western region had the highest variance in number of frost days.**

```{r}

region_df <- state_df |> 
  group_by(state_region) |> 
  summarize(mean(frost), sd(frost)) |> 
  rename(region = state_region, mean_frost = "mean(frost)", sd_frost = "sd(frost)")

print(region_df)

```

## Question 1.2

Is the mean number of frost days different in the North Central region than in the South? To answer this **by hand**, do the following:[^2]

[^2]: Hint: See lab 7 for help!

a.  State your null and alternative hypotheses

    **The null hypothesis: The mean number of frost days in the North Central region is the same as the mean number of frost days in the South. (ie. mean frost days in North Central - mean frost days in South = 0)**

    **The alternative hypothesis:** **There is a difference in the mean number of frost days in the North Central region and the South. (ie. mean frost days in North Central - mean frost days in the South != 0)**

b.  Compute a point estimate of your parameter of interest

    **The point estimate of interest is 74.21 average days with frost.**

c.  Compute your standard error and test statistic[^3]

    **The standard error is 10.43 deviations from the mean and the test statistic is 7.1.**

d.  Use `pt()` with 26 degrees of freedom[^4] to compute the *p*-value

    **The p-value is 1.49 x e\^-7.**

e.  Report whether you reject or fail to reject your null hypothesis at a significance level of $\alpha=0.05$

    **Given a significance level of 0.05, we can reject the null hypothesis as our p-value is less than 0.05 significance level.**

[^3]: Recall that the standard error for a difference in means is defined as: $SE = \sqrt{\frac{s_1^2}{n_1} + \frac{s^2_2}{n_2}}$ and the test-statistic for a hypothesis test is $z = \frac{\text{point estimate - null}}{SE}$

[^4]: Hint: Recall that `pt()` works just like `pnorm()`, but for the *t*-distribution instead of the normal distribution. Given our small sample size, we should use the *t*-distribution. The "degrees of freedom" is the parameter determining the shape of the *t* distribution. The degrees of freedom can be derived for a *t*-test with two groups with two different variances using the [Welch-Satterthwaite equation](https://en.wikipedia.org/wiki/Welch%E2%80%93Satterthwaite_equation). Don't bother calculating it, trust me it's *approximately* 26 for these data.

```{r}

### ---- Point Estimate -----

# computing mean for north central region
mu_n_central <- region_df |> 
  filter(region == "North Central") |> 
  select(mean_frost)

# computing mean for south region
mu_south <- region_df |> 
  filter(region == "South") |> 
  select(mean_frost)

# subracting these values for the point estimate
point_est <- as.numeric(mu_n_central - mu_south)
print(paste0("The point estimate is ", round(point_est, 4), "."))

### ---- Standard Error -----

# calculating the total number of states in that region
n_central <- state_df |> 
  filter(state_region == "North Central") |> 
  count()

n_south <- state_df |> 
  filter(state_region == "South") |> 
  count()

# calling out the standard deviation of frost days in that region
sd_central <- region_df |> 
  filter(region == "North Central") |> 
  select(sd_frost)

sd_south <- region_df |> 
  filter(region == "South") |> 
  select(sd_frost)

# using these valuse to compute the standard error
SE = as.numeric(sqrt(((sd_central^2) / n_central) + ((sd_south^2)/n_south)))
print((paste0("The standard error is ", SE, ".")))

### ----- TEST STATISTIC -----

#calculating the test statistic
test_stat = (point_est - 0) / SE
print(test_stat)


### ----- P-VALUE -----

p_val <- pt(test_stat,
            df = 26, 
            lower.tail = FALSE) * 2

print((paste0("The p-value is ", p_val, ".")))
```

## Question 1.3

Use your standard error to compute a 95% confidence interval around your point estimate. Interpret this confidence interval in words.

**There is a 95% probability that the range 53.76, 94.66 contains the difference in difference in average days of frost for states in the North Central region and South region.**

```{r}

# establishing the critical value for the quantile cut off points
crit_val = qnorm(0.025, lower.tail = FALSE)
crit_val

# creating the upper and lower confidence level points
ci_lower <- round(point_est - crit_val*SE, 2)
ci_upper <- round(point_est + crit_val*SE, 2)

print(paste0("95% probability that [", ci_lower, ", ", ci_upper, "] contains the difference in difference in average days of frost for states in the North Central region and South region."))

```

## Question 1.4

Repeat the hypothesis test in Question 1.2, this time using the function `t.test()` in `R`. Does this canned function lead you to the same conclusion as your manual calculation? Are there any differences in results? Why or why not?

**Running the t-test leads us to the same conclusion that we can reject the null hypothesis that the mean number of frost days in the North Central region is the same as the mean number of frost days in the South. However, the confidence interval range is larger as there is a lower degrees of freedom and thus would have a higher probability of extreme values and a wider confidence interval range.**

```{r}

# creating a dataframe with just South and North Central regions
state_df_south <- state_df |> 
  filter(state_region == "South") 
state_df_central <- state_df |> 
  filter(state_region == "North Central") 

state_df_ttest <- rbind(state_df_central, state_df_south)
nrow(state_df_ttest)

# conducting the ttest
ttest <- t.test(frost ~ state_region, data = state_df_ttest, conf.level = .95)
ttest
p_val_ttest <- (ttest$p.value)
print(p_val_ttest)

```

# Question 1.5

Prior evidence strongly suggests that the average number of frost days should be higher in the North Central region than in the South. Above, you conducted a two-tailed *t*-test with an alternative hypothesis that the difference in means across the two regions was not equal to zero.

Here, conduct a one-tailed *t*-test using `t.test()` following an alternative hypothesis that reflects this prior evidence. What is your new *p*-value? Why did it change in this way?

**The new p-value is 7. 47x e^-8^ for the one tailed t-test at a 95% confidence interval.** **In conducting a one tailed t-test we tested for the possibility that the relationship is positive and completely disregarding the possibility that the relationship could be negative.**

**Thus, the p-value is lower as we can be more confident in rejecting the null hypothesis given that we look at the alternative hypothesis that the difference in means for frost days in the North Central region minus the frost days in the South region is more than 0.**

```{r}

one_tail_ttest <- t.test(state_df_ttest$frost ~ state_df_ttest$state_region, paired = FALSE, alternative = "less", conf.level = .95)

p_val_onetail <- (one_tail_ttest$p.value)
print(paste0("The p-value for a one tailed t-test is ", p_val_onetail, "."))
```

# Question 2: Environmental determinants of crime

There is a large and growing body of evidence that environmental conditions influence crime.[^5] While researchers are still working to unpack the mechanisms between this link, hypothesized channels include impacts of temperature on emotion control, impacts of temperature and rainfall on economic activity, and impacts of a range of climate conditions on social interactions. In this problem, you will use the same data from Question 1 to investigate the link between murder rates and climate conditions across the United States.

[^5]: A review of this literature can be found [here](https://www.annualreviews.org/doi/abs/10.1146/annurev-economics-080614-115430).

## Question 2.1

To investigate the crime-climate link, run a simple linear regression of murder rate per 100,000 (contained in the `Murder` variable in the `state.x77` dataset) on the average number of frost days.

a.  Interpret the intercept and slope coefficients in words, paying close attention to units.[^6]

    **Intercept - The average mean number of days of frost with a minimum temperature below freezing in a capital or large city there is an average rate of 11.38 per 100,000 population of murder and non-negligent manslaughter in 1976.**

    **\
    Slope coefficient - For a one unit increase in average days of frost with a minimum temperature below freezing there is a decrease of 0.038 in the average rate of murder and non-negligent manslaughter per 100,000 population.\
    **

b.  Is there a statistically significant relationship between frost days on murder rates? At what significance level is this effect significant?

    **With a p-value of 4.4xe\^-5 the relationship between frost days on murder rates is a statistically significant at the 0.001 significance level (0.1% significance).**

c.  If you save your `lm` as a new object, you can access coefficients and standard errors in the `coefficients` list.[^7] Use these coefficients and standard errors to construct a 95% confidence interval for your slope coefficient. Interpret this confidence interval in words.

    **There is a 95% probability that the range -0.06, -0.02 contains the average rate of murder and non-negligent manslaughter per 100,000 population.**

d.  Now, construct a 90% confidence interval. How is the answer different than in the previous question? Why?

    **The answer is a smaller range for a 95% confidence interval compared to a 90% confidence variable. With the same point estimate we can have a higher confidence that the average rate of murder and non-negligent manslaughter per 100,000 population would fall in a wider range, compare to a narrower range. Thus, at a 95% confidence interval the range of values is larger.**

    ```{r}
    # running a simple linear regression
    mod_murder <- lm(formula = murder ~ frost, data = state_df)
    summary(mod_murder)

    # accessing coefficients and standard erros from regression output
    cr_val <- qnorm(0.025, lower.tail = FALSE)

    # pulling out the point estimates that we want
    point_est_murder <- mod_murder$coefficients["frost"]

    SE_murder <- 0.008635

    # creating the low and high interval
    int_low <- round(point_est_murder - cr_val*SE_murder, 2)
    int_high <- round(point_est_murder + cr_val*SE_murder, 2)

    print(paste0("95% probability that [", int_low, ", ", int_high, "] contains the average rate of murder and non-negligent manslaughter per 100,000 population."))


    #90 confidence level
    cr_val_90 <- cr_val <- qnorm(0.05, lower.tail = FALSE)

    # creating the low and high interval
    int_low_90 <- round(point_est_murder - cr_val_90*SE_murder, 2)
    int_high_90 <- round(point_est_murder + cr_val_90*SE_murder, 2)

    print(paste0("90% probability that [", int_low_90, ", ", int_high_90, "] contains the average rate of murder and non-negligent manslaughter per 100,000 population."))

    ```

[^6]: Use `?state.x77` to get more information about all the variables contained in this dataset.

[^7]: For example, if I saved my `lm` object as `model`, I could access coefficients and standard errors using `model$coefficients`. To access point estimates, you can use `model$coefficients[,"Estimate"]` and to access standard errors, you can use `model$coefficients[,"Std. Error"]`.

# Question 3: Lung disease in the UK

Here we are interested in the time series behavior of deaths from lung diseases in the UK. We believe it's likely that lung disease deaths have declined over time, as smoking has declined in prevalence and medical treatments for lung disease have improved. However, we also know that there is likely to be seasonality in these deaths, because respiratory diseases tend to be exacerbated by climatic conditions (e.g., see [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5819585/)). We want to pull apart this seasonal signal from the longer run trend.

## Question 3.1

First, load the `mdeaths` dataset in `R`, which contains a time series of monthly deaths from bronchitis, emphysema and asthma in the UK between 1974 and 1979 for males only. Convert this to a `tsibble` so that it's easier to work with various time series functions in `R`.

Then, make a simple time series plot. Do you see any visual evidence of a long-run trend? Any visual evidence of seasonality?

**There is strong visual evidence that monthly lung diseases deaths in the UK were affected by seasonality from 1974 to 1979. There is slight visual evidence that the long-run trend is decreasing as the dips in the summer months seem to be trending downward.**

```{r}

# loading in the data
mdeaths_plot <- mdeaths |> 
  as_tsibble() |> 
  rename("Date" = index, 
         "Deaths" = value)

# plotting the data
mdeaths_plot |> 
  autoplot(Deaths) +
  labs(title = "Male Monthly Lung Disease Deaths in the UK")

```

## Question 3.2

To recover seasonality separately from the long run trend, we will use a classical decomposition. That is, we wish to decompose total deaths $D_t$ into a trend component $T_t$, a seasonal component $S_t$, and a random component $R_t$. We will assume an additive model describes our data, as we don't see evidence in the above plot that the magnitude of seasonality is changing over time:

$$D_t = S_t + T_t + R_t$$

We could use moving averages to recover each of these components...**or** we could do this a lot more quickly using the `classical_decomposition()` function in the `feasts` package.[^8]

[^8]: Note: If `install.packages("feasts")` doesn't work for your version of `R`, try the development version from GitHub using `remotes::install_github("tidyverts/feasts")`.

Using this function with `autoplot()`, following the code in the time series lecture notes, make a plot which shows the time series in the raw data, the long run trend, the seasonal component, and the remainder random component.

a.  Is there any evidence of a long-run downward trend over time?

    **There is a long-run downward trend overtime in reduction of lung disease deaths, however, the magnitude of this downward trend in deaths over time appears to be negligible compared to the scale of the total deaths.**

b.  Is there any evidence of seasonality?

    **Looking at the graphs, there is evidence of seasonality influencing lung disease deaths. It appears to be that lung disease deaths were cyclically lower during summer months and higher during winter months each year from 1974 to 1980.**

c.  The grey bars on the side of the decomposition plot are there to help you assess how "big" each component is. Since the *y*-axes vary across each plot, it's hard to compare the magnitude of a trend or a seasonal cycle across plots without these grey bars. All grey bars are of the same magnitude; here, about 250. Thus, when the bar is small relative to the variation shown in a plot, that means that component is quantitatively important in determining overall variation. Based on the size of the bars, is the long-run trend or the seasonal component more important in driving overall variation in male lung disease deaths?

    **It appears that the seasonal component is a more important driving factor than a long-run trend as the scale of the gray bar on the x-axis is more similar to the time series plot of deaths without any factors taken out.**

```{r}
decom <- mdeaths_plot |> 
  model(classical_decomposition(Deaths, type = "additive")) |> 
  components() |> 
  autoplot() +
  labs(title = "Classical additive decomposition of monthly male lung disease deaths in the UK (1974 and 1979)")

decom
```

## Question 3.3

The decomposition above shows substantial seasonality in male lung disease deaths. To more precisely assess the nature of this seasonality, here I have estimated and plotted an autocorrelation function with a maximum of 12 lags (because we think the seasonality is likely occurring within the 12 month annual window of time).

```{r}

ukts = as_tsibble(mdeaths)
acf(ukts, lag.max = 12)

```

Reading off the plot above, answer the following:

a.  Is there a correlation between month $t$ and month $t-2$? Is it positive or negative? Is that correlation statistically significant at the 95% level?

    **There is a correlation between month t and t-2. It is positive correlation and appears to be statistically significant at the 95% confidence level.**

b.  What about the correlation between month $t$ and month $t-6$? What is the intuitive reason for the sign of this correlation?

    **There is a negative correlation between t and t-6 and this makes sense because summer and winter span 6 month timeframes and in comparing winter deaths with summer deaths in the timeseries and seasonal decomposition graphs, we saw there were less deaths during summer months than winter months.**

c.  Which month lags are statistically **insignificant**?

    **The month t-3 and month t-9 have a correlation that is statistically insignificant at a 95% confidence interval.**
